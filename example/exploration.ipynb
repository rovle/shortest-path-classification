{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "e07aa1bdf3c199e9827741020ccd72fe73595db2f08d591d80796aa8df0d9d5d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Learning languages from a single message\n",
    "\n",
    "In this example we'll see how this algorithm has the power to accurately identify languages after seeing messages of very short length. First we import everything that we're going to be using throughout the notebook."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "import sys\r\n",
    "from statistics import median, mean\r\n",
    "from itertools import combinations, product\r\n",
    "from collections import defaultdict\r\n",
    "from random import shuffle, sample, seed\r\n",
    "\r\n",
    "import networkx as nx\r\n",
    "from networkx.algorithms.shortest_paths.weighted import single_source_dijkstra\r\n",
    "\r\n",
    "if os.getcwd()[-7:] == 'example':\r\n",
    "    os.chdir(\"..\")\r\n",
    "\r\n",
    "from algorithm.base import ShortestPathModel\r\n",
    "\r\n",
    "from example.dataset_utils.sample_dataset import sample_dataset\r\n",
    "\r\n",
    "\r\n",
    "seed(42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Differentiating between English, French, Italian and German\r\n",
    "\r\n",
    "For our first example, we're just going to take 4 languages and see how well our algorithm works on differentiating messages of varying length in these languages. We're going to stress-test the algorithm  with varying scenarios, but let us just first try it out on a simple example of a thousand messages from each of these languages, each 10 words long."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "num_samples = 2000\r\n",
    "samples = {\r\n",
    "    'english' : sample_dataset(num_samples, 10, 'en'),\r\n",
    "    'french' : sample_dataset(num_samples, 10, 'fr'),\r\n",
    "    'italian' : sample_dataset(num_samples, 10, 'it'),\r\n",
    "    'german' : sample_dataset(num_samples, 10, 'de')\r\n",
    "    }\r\n",
    "    \r\n",
    "languages = samples.keys()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we define the similarity score function. This function is the crux of this whole model ..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def similarity_score(string1, string2):\r\n",
    "    intersection = [x for x in string1 if x in string2]\r\n",
    "    if len(intersection) == 0:\r\n",
    "        return float('inf')\r\n",
    "    else:\r\n",
    "        return 1/(len(intersection) ** 0.8)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "accuracies = []\r\n",
    "\r\n",
    "for language_anchor, language_other in product(languages, repeat=2):\r\n",
    "    if language_anchor == language_other:\r\n",
    "        continue\r\n",
    "    print(f'Using an example in {language_anchor} to differentiate that language from {language_other}...')\r\n",
    "\r\n",
    "    model = ShortestPathModel(similarity_score)\r\n",
    "\r\n",
    "    current_sample = samples[language_anchor] + samples[language_other]\r\n",
    "    labels = (len(samples[language_anchor]) * [1] +\r\n",
    "                len(samples[language_other]) * [0] )\r\n",
    "    n_of_labels = len(labels)\r\n",
    "    \r\n",
    "    model.fit_predict(current_sample)\r\n",
    "\r\n",
    "    # For calculating accuracy, take all but the first example, since\r\n",
    "    # that is the known one\r\n",
    "    accuracy = sum([1 if (labels[i] == model.predictions_on_train_set[i])\r\n",
    "                    else 0\r\n",
    "                    for i in range(n_of_labels)][1:]) / (n_of_labels - 1)\r\n",
    "    accuracies.append(accuracy)\r\n",
    "    print(f\"Accuracy: {100*accuracy}%\")\r\n",
    "    \r\n",
    "print(f\"\"\"Final report\r\n",
    "---------\r\n",
    "Mean accuracy is {100*mean(accuracies)}% and median is {100*median(accuracies)}%,\r\n",
    "minimum accuracy is {100*min(accuracies)}% and maximum accuracy is {100*max(accuracies)}%\r\n",
    "---------\"\"\")   \r\n",
    "    \r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using an example in english to differentiate that language from french...\n",
      "Accuracy: 96.64916229057265%\n",
      "Using an example in english to differentiate that language from italian...\n",
      "Accuracy: 95.72393098274569%\n",
      "Using an example in english to differentiate that language from german...\n",
      "Accuracy: 96.72418104526132%\n",
      "Using an example in french to differentiate that language from english...\n",
      "Accuracy: 99.32483120780195%\n",
      "Using an example in french to differentiate that language from italian...\n",
      "Accuracy: 80.32008002000501%\n",
      "Using an example in french to differentiate that language from german...\n",
      "Accuracy: 92.07301825456365%\n",
      "Using an example in italian to differentiate that language from english...\n",
      "Accuracy: 85.4463615903976%\n",
      "Using an example in italian to differentiate that language from french...\n",
      "Accuracy: 76.69417354338584%\n",
      "Using an example in italian to differentiate that language from german...\n",
      "Accuracy: 89.59739934983746%\n",
      "Using an example in german to differentiate that language from english...\n",
      "Accuracy: 96.42410602650664%\n",
      "Using an example in german to differentiate that language from french...\n",
      "Accuracy: 96.87421855463866%\n",
      "Using an example in german to differentiate that language from italian...\n",
      "Accuracy: 96.7491872968242%\n",
      "Final report\n",
      "---------\n",
      "Mean accuracy is 91.88338751354506% and median is 96.07401850462615%,\n",
      "minimum accuracy is 76.69417354338584% and maximum accuracy is 99.32483120780195%\n",
      "---------\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Playing with hyperparameters\r\n",
    "\r\n",
    "In the above example, we've seen that the model works well when given 1000 messages of length 10 in one language, and with the "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ]
}