{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "e07aa1bdf3c199e9827741020ccd72fe73595db2f08d591d80796aa8df0d9d5d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Learning languages from a single message\n",
    "\n",
    "In this example we'll see how this algorithm has the power to accurately identify languages after seeing messages of very short length. First we import everything that we're going to be using throughout the notebook."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "import os\r\n",
    "import sys\r\n",
    "from statistics import median\r\n",
    "from itertools import combinations, product\r\n",
    "from collections import defaultdict\r\n",
    "from random import shuffle, sample, seed\r\n",
    "\r\n",
    "import networkx as nx\r\n",
    "from networkx.algorithms.shortest_paths.weighted import single_source_dijkstra\r\n",
    "\r\n",
    "if os.getcwd()[-7:] == 'example':\r\n",
    "    os.chdir(\"..\")\r\n",
    "\r\n",
    "from algorithm.base import ShortestPathModel\r\n",
    "\r\n",
    "from example.dataset_utils.sample_dataset import sample_dataset\r\n",
    "\r\n",
    "\r\n",
    "seed(42)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Differentiating between English, French, Italian and German\n",
    "\n",
    "For our first example, we're just going to take 4 languages and see how well our algorithm works on differentiating messages of varying length in these languages. We're going to stress-test the algorithm  with varying scenarios, but let us just first try it out on a simple example of a thousand messages from each of these languages, each 10 words long."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "num_samples = 3000\r\n",
    "samples = {\r\n",
    "    'english' : sample_dataset(num_samples, 10, 'en'),\r\n",
    "    'french' : sample_dataset(num_samples, 10, 'fr'),\r\n",
    "    'italian' : sample_dataset(num_samples, 10, 'it'),\r\n",
    "    'german' : sample_dataset(num_samples, 10, 'de')\r\n",
    "    }\r\n",
    "    \r\n",
    "languages = samples.keys()"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20120/695847677.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m samples = {\n\u001b[0;32m      3\u001b[0m     \u001b[1;34m'english'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0msample_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'en'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[1;34m'french'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0msample_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'fr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;34m'italian'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0msample_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'it'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;34m'german'\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0msample_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'de'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lpesut\\shortest-path-classification\\example\\dataset_utils\\sample_dataset.py\u001b[0m in \u001b[0;36msample_dataset\u001b[1;34m(n, length, language, random_state)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Number of samples desired is larger than the number of samples possible ({num_of_samples}).\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_of_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lpesut\\shortest-path-classification\\example\\dataset_utils\\sample_dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Number of samples desired is larger than the number of samples possible ({num_of_samples}).\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_of_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[0msamples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we define the similarity score function. This functions is the crux of this whole model ..."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "languages"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['english', 'french', 'italian', 'german'])"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def similarity_score(string1, string2):\r\n",
    "    #string1 = string1.split(' ')\r\n",
    "    #string2 = string2.split(' ')\r\n",
    "    intersection = [x for x in string1 if x in string2]\r\n",
    "    if len(intersection) == 0:\r\n",
    "        return float('inf')\r\n",
    "    else:\r\n",
    "        return 1/(len(intersection) ** 4)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "model = ShortestPathModel(similarity_score)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "for language_anchor, language_other in product(languages, repeat=2):\r\n",
    "    if language_anchor == language_other:\r\n",
    "        continue\r\n",
    "    print(f'Language anchor: {language_anchor}, Other language: {language_other}')\r\n",
    "\r\n",
    "    model = ShortestPathModel(similarity_score)\r\n",
    "\r\n",
    "    current_sample = samples[language_anchor] + samples[language_other]\r\n",
    "    labels = (len(samples[language_anchor]) * [1] +\r\n",
    "                len(samples[language_other]) * [0] )\r\n",
    "    n_of_labels = len(labels)\r\n",
    "    \r\n",
    "    model.fit_predict(current_sample)\r\n",
    "\r\n",
    "    hits = [1 if (labels[i] == model.predictions_on_train_set[i]) else 0\r\n",
    "                for i in range(n_of_labels)]\r\n",
    "    print(f\"Accuracy score {hits/n_of_labels}%\")\r\n",
    "    \r\n",
    "    \r\n",
    "    \r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Language anchor: english, Other language: french\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20120/2991962181.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mn_of_labels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_sample\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     hits = [1 if (labels[i] == model.predictions_on_train_set[i]) else 0\n",
      "\u001b[1;32mc:\\Users\\lpesut\\shortest-path-classification\\algorithm\\base.py\u001b[0m in \u001b[0;36mfit_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfit_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[0mn_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredictions_on_train_set\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\lpesut\\shortest-path-classification\\algorithm\\base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m     22\u001b[0m                                             x_2.features)\n\u001b[0;32m     23\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0msimilarity\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'inf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m                 self.graph.add_edge(str(x_1.index), str(x_2.index),\n\u001b[0m\u001b[0;32m     25\u001b[0m                                 weight=similarity)\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "for language_anchor, language_other in product(languages, repeat=2):\r\n",
    "    if language_anchor == language_other:\r\n",
    "        continue\r\n",
    "    print(f'Language anchor: {language_anchor}, Other language: {language_other}')\r\n",
    "    current_sample = samples[language_anchor] + samples[language_other]\r\n",
    "    current_sample = list(enumerate(current_sample))\r\n",
    "    graph = []\r\n",
    "    for combination in combinations(current_sample, 2):\r\n",
    "        similarity = similarity_score(combination[0][1], combination[1][1])\r\n",
    "        if similarity == float('inf'):\r\n",
    "            continue\r\n",
    "        graph.append( ( combination[0][0], combination[1][0],\r\n",
    "                similarity_score(combination[0][1], combination[1][1]) ) )\r\n",
    "    \r\n",
    "    G = nx.Graph()\r\n",
    "\r\n",
    "    for edge in graph:\r\n",
    "        G.add_edge(str(edge[0]), str(edge[1]), weight=edge[2])\r\n",
    "\r\n",
    "    distances = single_source_dijkstra(G, '0')[0]\r\n",
    "    medijan = median(distances.values())\r\n",
    "    predicted_labels = []\r\n",
    "    for x in range(num_samples*2):\r\n",
    "        if x == 0:\r\n",
    "            continue\r\n",
    "        if distances[str(x)] > medijan:\r\n",
    "            predicted_labels.append(1)\r\n",
    "        else:\r\n",
    "            predicted_labels.append(0)\r\n",
    "\r\n",
    "    labelss = [0 if x < num_samples-1 else 1 for x in range(num_samples-1)]\r\n",
    "    truth = [1 if (predicted_labels[x] == labelss[x]) else 0 for x in range(num_samples-1)]\r\n",
    "    print(sum(truth))\r\n",
    "    print(f'Accuracy: {sum(truth)/(num_samples-1)}')\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Language anchor: english, Other language: french\n",
      "2888\n",
      "Accuracy: 0.9629876625541848\n",
      "Language anchor: english, Other language: italian\n",
      "2406\n",
      "Accuracy: 0.802267422474158\n",
      "Language anchor: english, Other language: german\n",
      "2406\n",
      "Accuracy: 0.802267422474158\n",
      "Language anchor: french, Other language: english\n",
      "2832\n",
      "Accuracy: 0.9443147715905301\n",
      "Language anchor: french, Other language: italian\n",
      "2848\n",
      "Accuracy: 0.9496498832944315\n",
      "Language anchor: french, Other language: german\n",
      "2838\n",
      "Accuracy: 0.9463154384794932\n",
      "Language anchor: italian, Other language: english\n",
      "2340\n",
      "Accuracy: 0.7802600866955652\n",
      "Language anchor: italian, Other language: french\n",
      "2419\n",
      "Accuracy: 0.8066022007335779\n",
      "Language anchor: italian, Other language: german\n",
      "2857\n",
      "Accuracy: 0.952650883627876\n",
      "Language anchor: german, Other language: english\n",
      "2509\n",
      "Accuracy: 0.8366122040680227\n",
      "Language anchor: german, Other language: french\n",
      "2513\n",
      "Accuracy: 0.837945981993998\n",
      "Language anchor: german, Other language: italian\n",
      "2751\n",
      "Accuracy: 0.9173057685895298\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}