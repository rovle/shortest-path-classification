{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('shortest-path': conda)"
  },
  "interpreter": {
   "hash": "e4724c4f1193458327c9fd27e93e82201b4f22d46bfd685926396a0b7f3503db"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Learning languages from a single message\n",
    "\n",
    "In this example we'll see how this algorithm has the power to accurately identify languages after seeing messages of very short length. First we import everything that we're going to be using throughout the notebook."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from statistics import median\n",
    "from itertools import combinations, product\n",
    "from collections import defaultdict\n",
    "from random import shuffle, sample, seed\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from networkx.algorithms.shortest_paths.weighted import single_source_dijkstra\n",
    "\n",
    "sys.path.append('example/dataset_utils')\n",
    "from sample_dataset import sample_dataset\n",
    "\n",
    "\n",
    "seed(42)"
   ]
  },
  {
   "source": [
    "### Differentiating between English, French, Italian and German\n",
    "\n",
    "For our first example, we're just going to take 4 languages and see how well our algorithm works on differentiating messages of varying length in these languages. We're going to stress-test the algorithm  with varying scenarios, but let us just first try it out on a simple example of a thousand messages from each of these languages, each 10 words long."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 3000\n",
    "samples = {\n",
    "    'english' : sample_dataset(num_samples, 10, 'en'),\n",
    "    'french' : sample_dataset(num_samples, 10, 'fr'),\n",
    "    'italian' : sample_dataset(num_samples, 10, 'it'),\n",
    "    'german' : sample_dataset(num_samples, 10, 'de')\n",
    "    }\n",
    "    \n",
    "languages = samples.keys()"
   ]
  },
  {
   "source": [
    "Now we define the similarity score function. This functions is the crux of this whole model ..."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['english', 'french', 'italian', 'german'])"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_score(string1, string2):\n",
    "    #string1 = string1.split(' ')\n",
    "    #string2 = string2.split(' ')\n",
    "    intersection = [x for x in string1 if x in string2]\n",
    "    if len(intersection) == 0:\n",
    "        return float('inf')\n",
    "    else:\n",
    "        return 1/(len(intersection) ** 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Language anchor: english, Other language: french\n",
      "2888\n",
      "Accuracy: 0.9629876625541848\n",
      "Language anchor: english, Other language: italian\n",
      "2406\n",
      "Accuracy: 0.802267422474158\n",
      "Language anchor: english, Other language: german\n",
      "2406\n",
      "Accuracy: 0.802267422474158\n",
      "Language anchor: french, Other language: english\n",
      "2832\n",
      "Accuracy: 0.9443147715905301\n",
      "Language anchor: french, Other language: italian\n",
      "2848\n",
      "Accuracy: 0.9496498832944315\n",
      "Language anchor: french, Other language: german\n",
      "2838\n",
      "Accuracy: 0.9463154384794932\n",
      "Language anchor: italian, Other language: english\n",
      "2340\n",
      "Accuracy: 0.7802600866955652\n",
      "Language anchor: italian, Other language: french\n",
      "2419\n",
      "Accuracy: 0.8066022007335779\n",
      "Language anchor: italian, Other language: german\n",
      "2857\n",
      "Accuracy: 0.952650883627876\n",
      "Language anchor: german, Other language: english\n",
      "2509\n",
      "Accuracy: 0.8366122040680227\n",
      "Language anchor: german, Other language: french\n",
      "2513\n",
      "Accuracy: 0.837945981993998\n",
      "Language anchor: german, Other language: italian\n",
      "2751\n",
      "Accuracy: 0.9173057685895298\n"
     ]
    }
   ],
   "source": [
    "for language_anchor, language_other in product(languages, repeat=2):\n",
    "    if language_anchor == language_other:\n",
    "        continue\n",
    "    print(f'Language anchor: {language_anchor}, Other language: {language_other}')\n",
    "    current_sample = samples[language_anchor] + samples[language_other]\n",
    "    current_sample = list(enumerate(current_sample))\n",
    "    graph = []\n",
    "    for combination in combinations(current_sample, 2):\n",
    "        similarity = similarity_score(combination[0][1], combination[1][1])\n",
    "        if similarity == float('inf'):\n",
    "            continue\n",
    "        graph.append( ( combination[0][0], combination[1][0],\n",
    "                similarity_score(combination[0][1], combination[1][1]) ) )\n",
    "    \n",
    "    G = nx.Graph()\n",
    "\n",
    "    for edge in graph:\n",
    "        G.add_edge(str(edge[0]), str(edge[1]), weight=edge[2])\n",
    "\n",
    "    distances = single_source_dijkstra(G, '0')[0]\n",
    "    medijan = median(distances.values())\n",
    "    predicted_labels = []\n",
    "    for x in range(num_samples*2):\n",
    "        if x == 0:\n",
    "            continue\n",
    "        if distances[str(x)] > medijan:\n",
    "            predicted_labels.append(1)\n",
    "        else:\n",
    "            predicted_labels.append(0)\n",
    "\n",
    "    labelss = [0 if x < num_samples-1 else 1 for x in range(num_samples-1)]\n",
    "    truth = [1 if (predicted_labels[x] == labelss[x]) else 0 for x in range(num_samples-1)]\n",
    "    print(sum(truth))\n",
    "    print(f'Accuracy: {sum(truth)/(num_samples-1)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_list = samples_limited['en'] + samples_limited['es']\n",
    "\n",
    "x = list(enumerate(combined_list))\n",
    "shuffle(x)\n",
    "indices, combined_list = zip(*x)\n",
    "\n",
    "labels = [0 if y < n_of_samples else 1 for y in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((454, 773, 198, 609, 450, 1255, 1765, 985, 143, 816),\n",
       " [0, 0, 0, 0, 0, 1, 1, 0, 0, 0],\n",
       " ('objective to reduce greenhouse gas experience I know that heading',\n",
       "  'benefit from social is that the Council did not agree',\n",
       "  'and to guarantee that the privacy of their communications is',\n",
       "  'the utmost we had to give reasons for the existence',\n",
       "  'we now all know is in no position to bring',\n",
       "  'ha aprendido la lección tras la crisis Donata Gottardi califica',\n",
       "  'justificación parece de sentido los recursos como el bacalao por',\n",
       "  'develop and the maintenance of ecosystems should become a fundamental',\n",
       "  'like to thank Mr Graefe zu Baringdorf for a very',\n",
       "  'Pacific entire dispute with the United has arisen because we'))"
      ]
     },
     "metadata": {},
     "execution_count": 170
    }
   ],
   "source": [
    "indices[:10], labels[:10], combined_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = []\n",
    "i = 0\n",
    "for combination in combinations(x, 2):\n",
    "    similarity = similarity_score(combination[0][1], combination[1][1])\n",
    "    if similarity == float('inf'):\n",
    "        continue\n",
    "    graph.append( ( combination[0][0], combination[1][0],\n",
    "            similarity_score(combination[0][1], combination[1][1]) ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "782798"
      ]
     },
     "metadata": {},
     "execution_count": 172
    }
   ],
   "source": [
    "len(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "for edge in graph:\n",
    "    G.add_edge(str(edge[0]), str(edge[1]), weight=edge[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms.shortest_paths.weighted import single_source_dijkstra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.014660493827160493\n"
     ]
    }
   ],
   "source": [
    "distances = single_source_dijkstra(G, '0')[0]\n",
    "medijan = median(distances.values())\n",
    "print(medijan)\n",
    "predicted_labels = []\n",
    "for x in range(n_of_samples*2):\n",
    "    if x == 0:\n",
    "        continue\n",
    "    if distances[str(x)] > medijan:\n",
    "        predicted_labels.append(1)\n",
    "    else:\n",
    "        predicted_labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelss = [0 if x < n_of_samples else 1 for x in range(n_of_samples-1)]\n",
    "truth = [1 if (predicted_labels[x] == labelss[x]) else 0 for x in range(n_of_samples-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.9259259259259259"
      ]
     },
     "metadata": {},
     "execution_count": 178
    }
   ],
   "source": [
    "sum(truth)/(n_of_samples-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}